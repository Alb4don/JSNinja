#!/usr/bin/env python3

import argparse
import hashlib
import html
import json
import logging
import os
import platform
import re
import shutil
import signal
import sys
import time
import urllib.parse
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Optional

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

__version__ = "1.0.0"
__tool_name__ = "JSNinja"
__author__ = "Security Research"

logging.basicConfig(
    level=logging.WARNING,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger(__tool_name__)

OLLAMA_BASE_URL = os.environ.get("OLLAMA_HOST", "http://127.0.0.1:11434")
OLLAMA_MODEL = "llama3.2:1b"
REQUEST_TIMEOUT = int(os.environ.get("JSNINJA_TIMEOUT", "15"))
MAX_WORKERS = int(os.environ.get("JSNINJA_WORKERS", "10"))
MAX_JS_SIZE_BYTES = 5 * 1024 * 1024
MAX_AI_CHUNK_CHARS = 3000

ANSI_RESET = "\033[0m"
ANSI_BOLD = "\033[1m"
ANSI_RED = "\033[91m"
ANSI_GREEN = "\033[92m"
ANSI_YELLOW = "\033[93m"
ANSI_CYAN = "\033[96m"
ANSI_MAGENTA = "\033[95m"
ANSI_BLUE = "\033[94m"
ANSI_DIM = "\033[2m"

SECRET_PATTERNS: dict[str, re.Pattern] = {
    "AWS Access Key": re.compile(r"(?<![A-Z0-9])AKIA[0-9A-Z]{16}(?![A-Z0-9])"),
    "AWS Secret Key": re.compile(r"(?i)aws.{0,20}secret.{0,20}['\"][0-9a-zA-Z/+]{40}['\"]"),
    "Google API Key": re.compile(r"AIza[0-9A-Za-z\-_]{35}"),
    "Google OAuth": re.compile(r"[0-9]+-[0-9A-Za-z_]{32}\.apps\.googleusercontent\.com"),
    "GitHub Token": re.compile(r"gh[pousr]_[A-Za-z0-9]{36,255}"),
    "Slack Token": re.compile(r"xox[baprs]-[0-9]{12}-[0-9]{12}-[0-9]{12}-[a-zA-Z0-9]{32}"),
    "Slack Webhook": re.compile(r"https://hooks\.slack\.com/services/T[a-zA-Z0-9]{8}/B[a-zA-Z0-9]{8,10}/[a-zA-Z0-9]{24}"),
    "Stripe Live Key": re.compile(r"sk_live_[0-9a-zA-Z]{24,}"),
    "Stripe Test Key": re.compile(r"sk_test_[0-9a-zA-Z]{24,}"),
    "SendGrid Key": re.compile(r"SG\.[a-zA-Z0-9\-_]{22}\.[a-zA-Z0-9\-_]{43}"),
    "Twilio Account SID": re.compile(r"AC[a-zA-Z0-9]{32}"),
    "Twilio Auth Token": re.compile(r"(?i)twilio.{0,20}['\"][a-zA-Z0-9]{32}['\"]"),
    "Firebase URL": re.compile(r"https://[a-zA-Z0-9\-]+\.firebaseio\.com"),
    "Firebase Key": re.compile(r"(?i)(firebase|firestore).{0,20}['\"][A-Za-z0-9\-_]{20,}['\"]"),
    "Private Key": re.compile(r"-----BEGIN (RSA|EC|DSA|OPENSSH) PRIVATE KEY-----"),
    "JWT": re.compile(r"eyJ[A-Za-z0-9\-_=]+\.[A-Za-z0-9\-_=]+\.[A-Za-z0-9\-_.+/=]*"),
    "Bearer Token": re.compile(r"(?i)bearer\s+[a-zA-Z0-9\-._~+/]{20,}"),
    "Basic Auth": re.compile(r"(?i)(Authorization|auth)\s*[:=]\s*['\"]Basic\s+[A-Za-z0-9+/=]{10,}['\"]"),
    "Password in Code": re.compile(r"(?i)(password|passwd|pwd)\s*[:=]\s*['\"][^'\"]{6,}['\"]"),
    "API Key Generic": re.compile(r"(?i)(api[_\-]?key|apikey|access[_\-]?key)\s*[:=]\s*['\"][a-zA-Z0-9\-_]{16,}['\"]"),
    "Secret Generic": re.compile(r"(?i)(secret|client[_\-]?secret)\s*[:=]\s*['\"][a-zA-Z0-9\-_]{16,}['\"]"),
    "NPM Token": re.compile(r"npm_[a-zA-Z0-9]{36}"),
    "Mailchimp Key": re.compile(r"[a-zA-Z0-9]{32}-us[0-9]{1,2}"),
    "HubSpot Key": re.compile(r"[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}"),
    "Cloudinary URL": re.compile(r"cloudinary://[a-zA-Z0-9]{15}:[a-zA-Z0-9_\-]+@[a-zA-Z0-9]+"),
    "Heroku API Key": re.compile(r"[hH]eroku.{0,20}[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}"),
    "Telegram Bot Token": re.compile(r"[0-9]{8,10}:[a-zA-Z0-9_-]{35}"),
}

ENDPOINT_PATTERNS: list[re.Pattern] = [
    re.compile(r"""(?:url|endpoint|path|href|src|action)\s*[:=]\s*['"`]([/][^'"`\s]{2,}['"`])""", re.IGNORECASE),
    re.compile(r"""fetch\s*\(\s*['"`]([^'"`\s]{2,})['"`]""", re.IGNORECASE),
    re.compile(r"""axios\s*\.\s*(?:get|post|put|delete|patch)\s*\(\s*['"`]([^'"`\s]{2,})['"`]""", re.IGNORECASE),
    re.compile(r"""XMLHttpRequest[^;]*\.open\s*\([^,]+,\s*['"`]([^'"`\s]{2,})['"`]""", re.IGNORECASE),
    re.compile(r"""['"`](/api/[^\s'"`?#]{2,})['"`]""", re.IGNORECASE),
    re.compile(r"""['"`](/v\d+/[^\s'"`?#]{2,})['"`]""", re.IGNORECASE),
    re.compile(r"""['"`](https?://[^\s'"`?#]{10,})['"`]""", re.IGNORECASE),
    re.compile(r"""['"`](/[a-zA-Z0-9_\-./]{3,50})['"`]"""),
]

DOMXSS_PATTERNS: list[tuple[str, re.Pattern]] = [
    ("document.write", re.compile(r"document\.write\s*\(", re.IGNORECASE)),
    ("innerHTML assignment", re.compile(r"\.innerHTML\s*=", re.IGNORECASE)),
    ("outerHTML assignment", re.compile(r"\.outerHTML\s*=", re.IGNORECASE)),
    ("eval()", re.compile(r"\beval\s*\(", re.IGNORECASE)),
    ("setTimeout string", re.compile(r"setTimeout\s*\(\s*['\"`]", re.IGNORECASE)),
    ("setInterval string", re.compile(r"setInterval\s*\(\s*['\"`]", re.IGNORECASE)),
    ("location.href", re.compile(r"location\.href\s*=", re.IGNORECASE)),
    ("location.assign", re.compile(r"location\.assign\s*\(", re.IGNORECASE)),
    ("location.replace", re.compile(r"location\.replace\s*\(", re.IGNORECASE)),
    ("window.open", re.compile(r"window\.open\s*\(", re.IGNORECASE)),
    ("document.URL sink", re.compile(r"document\.(URL|referrer|cookie)\s+[^;]*(?:innerHTML|eval|write)", re.IGNORECASE)),
    ("insertAdjacentHTML", re.compile(r"insertAdjacentHTML\s*\(", re.IGNORECASE)),
    ("jQuery html()", re.compile(r"\$\s*\([^)]+\)\s*\.html\s*\(", re.IGNORECASE)),
    ("jQuery append", re.compile(r"\$\s*\([^)]+\)\s*\.(append|prepend|after|before)\s*\(", re.IGNORECASE)),
    ("postMessage", re.compile(r"addEventListener\s*\(\s*['\"]message['\"]", re.IGNORECASE)),
    ("dangerouslySetInnerHTML", re.compile(r"dangerouslySetInnerHTML", re.IGNORECASE)),
    ("srcdoc assignment", re.compile(r"\.srcdoc\s*=", re.IGNORECASE)),
    ("Function constructor", re.compile(r"new\s+Function\s*\(", re.IGNORECASE)),
]

VARIABLE_PATTERN = re.compile(
    r"""(?:var|let|const)\s+([a-zA-Z_$][a-zA-Z0-9_$]*)\s*=\s*(?:document\.|window\.|location\.|['"`])""",
    re.IGNORECASE,
)

JS_LINK_PATTERN = re.compile(
    r"""(?:src|href|import|require)\s*[=(]\s*['"`]?([^'"`\s>)]+\.js(?:[?#][^'"`\s>)]*)?['"`]?)""",
    re.IGNORECASE,
)


def _supports_color() -> bool:
    if platform.system() == "Windows":
        try:
            import ctypes
            kernel32 = ctypes.windll.kernel32
            kernel32.SetConsoleMode(kernel32.GetStdHandle(-11), 7)
            return True
        except Exception:
            return "ANSICON" in os.environ or "WT_SESSION" in os.environ
    return hasattr(sys.stdout, "isatty") and sys.stdout.isatty()


USE_COLOR = _supports_color()


def c(text: str, *codes: str) -> str:
    if not USE_COLOR:
        return text
    return "".join(codes) + text + ANSI_RESET


def print_banner() -> None:
    banner_lines = [
        "",
        c(" ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó     ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ", ANSI_CYAN, ANSI_BOLD),
        c(" ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó", ANSI_CYAN, ANSI_BOLD),
        c(" ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë", ANSI_CYAN, ANSI_BOLD),
        c(" ‚ñà‚ñà‚ïë‚ïö‚ïê‚ïê‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë", ANSI_BLUE, ANSI_BOLD),
        c(" ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë", ANSI_BLUE, ANSI_BOLD),
        c(" ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù", ANSI_BLUE, ANSI_BOLD),
        "",
        c("  JavaScript Reconnaissance & AI Analysis Engine", ANSI_YELLOW, ANSI_BOLD),
        c(f"  Version {__version__} | Powered by Llama 3.2 via Ollama", ANSI_DIM),
        c("  For authorized security testing only.", ANSI_RED),
        "",
    ]
    for line in banner_lines:
        print(line)

    print(c("  Capabilities:", ANSI_CYAN, ANSI_BOLD))
    caps = [
        ("JS Discovery",     "Crawl & collect JavaScript file URLs"),
        ("Endpoint Mining",  "Extract API paths and HTTP endpoints"),
        ("Secret Hunting",   "Detect 25+ secret/key patterns"),
        ("DOM XSS Analysis", "Identify dangerous DOM sinks"),
        ("Variable Recon",   "Extract JS variables for XSS research"),
        ("Wordlist Builder", "Generate target-specific wordlists"),
        ("AI Insights",      "Context-aware analysis with Llama 3.2"),
        ("HTML Report",      "Full structured recon report"),
    ]
    for name, desc in caps:
        print(f"  {c('‚ñ∫', ANSI_GREEN)} {c(name, ANSI_BOLD):<22} {c(desc, ANSI_DIM)}")
    print()


def _confirm_interactive(prompt: str) -> bool:
    try:
        answer = input(f"{c('  [?]', ANSI_YELLOW)} {prompt} {c('[y/N]', ANSI_DIM)}: ").strip().lower()
        return answer in ("y", "yes")
    except (EOFError, KeyboardInterrupt):
        return False


@dataclass
class ScanResult:
    js_links: list[str] = field(default_factory=list)
    endpoints: dict[str, list[str]] = field(default_factory=dict)
    secrets: dict[str, list[dict]] = field(default_factory=dict)
    domxss: dict[str, list[dict]] = field(default_factory=dict)
    variables: dict[str, list[str]] = field(default_factory=dict)
    wordlist: list[str] = field(default_factory=list)
    local_files: list[str] = field(default_factory=list)
    ai_analysis: dict[str, str] = field(default_factory=dict)
    errors: list[str] = field(default_factory=list)
    scan_start: float = field(default_factory=time.time)


def _build_session() -> requests.Session:
    session = requests.Session()
    retry = Retry(
        total=3,
        backoff_factor=0.5,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET", "HEAD"],
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (compatible; JSNinja-Scanner/1.0; Security-Research)",
        "Accept": "text/html,application/xhtml+xml,application/javascript,*/*;q=0.9",
        "Accept-Language": "en-US,en;q=0.9",
        "Accept-Encoding": "gzip, deflate",
        "Connection": "close",
    })
    return session


_session: Optional[requests.Session] = None


def get_session() -> requests.Session:
    global _session
    if _session is None:
        _session = _build_session()
    return _session


def _sanitize_url(url: str) -> Optional[str]:
    url = url.strip()
    try:
        parsed = urllib.parse.urlparse(url)
        if parsed.scheme not in ("http", "https"):
            return None
        host = parsed.hostname or ""
        if not host or host in ("localhost", "127.0.0.1", "::1"):
            return None
        if re.search(r"[<>\"'`\x00-\x1f]", url):
            return None
        return url
    except Exception:
        return None


def _safe_filename(url: str) -> str:
    h = hashlib.sha256(url.encode()).hexdigest()[:12]
    name = re.sub(r"[^a-zA-Z0-9\-_.]", "_", urllib.parse.urlparse(url).path.split("/")[-1] or "index")
    return f"{name[:40]}_{h}.js"


def _fetch_url(url: str, max_size: int = MAX_JS_SIZE_BYTES) -> Optional[str]:
    safe = _sanitize_url(url)
    if not safe:
        return None
    try:
        resp = get_session().get(safe, timeout=REQUEST_TIMEOUT, stream=True, allow_redirects=True)
        if resp.status_code != 200:
            return None
        content_type = resp.headers.get("Content-Type", "")
        if "html" in content_type and ".js" not in url:
            return None
        chunks = []
        total = 0
        for chunk in resp.iter_content(chunk_size=8192, decode_unicode=False):
            if chunk:
                total += len(chunk)
                if total > max_size:
                    return None
                chunks.append(chunk)
        raw = b"".join(chunks)
        return raw.decode("utf-8", errors="replace")
    except requests.RequestException:
        return None
    except Exception:
        return None


def _status(msg: str, level: str = "info") -> None:
    icons = {"info": c("[*]", ANSI_CYAN), "ok": c("[+]", ANSI_GREEN), "warn": c("[!]", ANSI_YELLOW), "err": c("[-]", ANSI_RED)}
    print(f"  {icons.get(level, icons['info'])} {msg}")


def gather_js_links_from_page(target_url: str) -> list[str]:
    safe = _sanitize_url(target_url)
    if not safe:
        return []
    _status(f"Crawling: {c(safe, ANSI_CYAN)}")
    content = _fetch_url(safe, max_size=10 * 1024 * 1024)
    if not content:
        return []

    parsed_base = urllib.parse.urlparse(safe)
    base = f"{parsed_base.scheme}://{parsed_base.netloc}"

    raw_links: set[str] = set()

    for match in JS_LINK_PATTERN.finditer(content):
        link = match.group(1).strip().strip("\"'`")
        if link:
            raw_links.add(link)

    inline_js = re.findall(r"['\"`]([^'\"`\s]*\.js(?:[?#][^'\"`\s]*)?)['\"`]", content)
    raw_links.update(inline_js)

    resolved: list[str] = []
    for link in raw_links:
        try:
            full = urllib.parse.urljoin(base, link)
            sanitized = _sanitize_url(full)
            if sanitized and sanitized.endswith((".js",)) or ".js?" in sanitized or ".js#" in sanitized:
                resolved.append(sanitized)
        except Exception:
            continue

    return list(set(resolved))


def discover_js_links(targets: list[str], result: ScanResult) -> None:
    _status("Starting JS link discovery phase...", "info")
    found: set[str] = set()
    with ThreadPoolExecutor(max_workers=min(MAX_WORKERS, len(targets) or 1)) as ex:
        futures = {ex.submit(gather_js_links_from_page, t): t for t in targets}
        for future in as_completed(futures):
            try:
                links = future.result()
                found.update(links)
                if links:
                    _status(f"Found {c(str(len(links)), ANSI_GREEN)} JS links from {futures[future]}", "ok")
            except Exception as exc:
                result.errors.append(f"Link discovery error: {exc}")
    result.js_links = sorted(found)
    _status(f"Total JS links collected: {c(str(len(result.js_links)), ANSI_GREEN)}", "ok")


def extract_endpoints_from_js(js_url: str, content: str) -> list[str]:
    found: set[str] = set()
    for pattern in ENDPOINT_PATTERNS:
        for match in pattern.finditer(content):
            ep = match.group(1).strip()
            if len(ep) < 3 or len(ep) > 300:
                continue
            if re.search(r"[<>\"'\x00-\x1f]", ep):
                continue
            if ep.startswith(("//", "data:", "blob:", "javascript:")):
                continue
            found.add(ep)
    return sorted(found)


def find_secrets_in_js(js_url: str, content: str) -> list[dict]:
    found: list[dict] = []
    seen: set[str] = set()
    lines = content.splitlines()
    for line_num, line in enumerate(lines, start=1):
        for secret_type, pattern in SECRET_PATTERNS.items():
            for match in pattern.finditer(line):
                value = match.group(0)
                dedup_key = f"{secret_type}:{hashlib.md5(value.encode()).hexdigest()}"
                if dedup_key in seen:
                    continue
                seen.add(dedup_key)
                context = line.strip()[:200]
                found.append({
                    "type": secret_type,
                    "line": line_num,
                    "value": value[:80] + ("..." if len(value) > 80 else ""),
                    "context": context,
                })
    return found


def scan_domxss(js_url: str, content: str) -> list[dict]:
    found: list[dict] = []
    lines = content.splitlines()
    for line_num, line in enumerate(lines, start=1):
        for sink_name, pattern in DOMXSS_PATTERNS:
            if pattern.search(line):
                found.append({
                    "sink": sink_name,
                    "line": line_num,
                    "context": line.strip()[:200],
                })
    return found


def extract_variables(js_url: str, content: str) -> list[str]:
    found: set[str] = set()
    for match in VARIABLE_PATTERN.finditer(content):
        var_name = match.group(1)
        if 2 <= len(var_name) <= 50:
            found.add(var_name)
    return sorted(found)


def build_wordlist_from_js(content: str) -> list[str]:
    raw_words = re.findall(r"[a-zA-Z_][a-zA-Z0-9_]{3,}", content)
    stop_words = {
        "function", "return", "const", "let", "var", "true", "false", "null",
        "undefined", "this", "window", "document", "console", "prototype",
        "constructor", "length", "push", "slice", "split", "join", "replace",
        "match", "search", "string", "number", "boolean", "object", "array",
        "typeof", "instanceof", "class", "extends", "import", "export",
        "default", "async", "await", "promise", "resolve", "reject",
    }
    return sorted({w.lower() for w in raw_words if w.lower() not in stop_words and len(w) <= 40})


def process_js_file(
    js_url: str,
    output_dir: Optional[Path],
    result: ScanResult,
    do_endpoints: bool,
    do_secrets: bool,
    do_domxss: bool,
    do_variables: bool,
    do_wordlist: bool,
    do_local: bool,
) -> None:
    content = _fetch_url(js_url)
    if not content:
        result.errors.append(f"Failed to fetch: {js_url}")
        return

    if do_endpoints:
        eps = extract_endpoints_from_js(js_url, content)
        if eps:
            result.endpoints[js_url] = eps

    if do_secrets:
        secs = find_secrets_in_js(js_url, content)
        if secs:
            result.secrets[js_url] = secs

    if do_domxss:
        sinks = scan_domxss(js_url, content)
        if sinks:
            result.domxss[js_url] = sinks

    if do_variables:
        variables = extract_variables(js_url, content)
        if variables:
            result.variables[js_url] = variables

    if do_wordlist:
        words = build_wordlist_from_js(content)
        result.wordlist.extend(words)

    if do_local and output_dir:
        local_path = output_dir / "jsfiles" / _safe_filename(js_url)
        local_path.parent.mkdir(parents=True, exist_ok=True)
        try:
            local_path.write_text(content, encoding="utf-8", errors="replace")
            result.local_files.append(str(local_path))
        except OSError:
            pass


def run_scan(
    js_links: list[str],
    output_dir: Optional[Path],
    result: ScanResult,
    do_endpoints: bool,
    do_secrets: bool,
    do_domxss: bool,
    do_variables: bool,
    do_wordlist: bool,
    do_local: bool,
) -> None:
    _status(f"Processing {c(str(len(js_links)), ANSI_GREEN)} JS files...", "info")
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        futures = {
            ex.submit(
                process_js_file,
                url,
                output_dir,
                result,
                do_endpoints,
                do_secrets,
                do_domxss,
                do_variables,
                do_wordlist,
                do_local,
            ): url
            for url in js_links
        }
        done = 0
        for future in as_completed(futures):
            done += 1
            url = futures[future]
            try:
                future.result()
                if done % 10 == 0 or done == len(js_links):
                    _status(f"Progress: {c(str(done), ANSI_GREEN)}/{len(js_links)}", "info")
            except Exception as exc:
                result.errors.append(f"Processing {url}: {exc}")

    if do_wordlist:
        result.wordlist = sorted(set(result.wordlist))


def _check_ollama_available() -> bool:
    try:
        resp = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
        return resp.status_code == 200
    except Exception:
        return False


def _check_model_available() -> bool:
    try:
        resp = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
        if resp.status_code != 200:
            return False
        data = resp.json()
        models = [m.get("name", "") for m in data.get("models", [])]
        return any(OLLAMA_MODEL in m or m.startswith("llama3.2:1b") for m in models)
    except Exception:
        return False


def _pull_model_if_needed() -> bool:
    if _check_model_available():
        return True
    _status(f"Pulling {OLLAMA_MODEL} (this may take a moment)...", "warn")
    try:
        resp = requests.post(
            f"{OLLAMA_BASE_URL}/api/pull",
            json={"name": OLLAMA_MODEL},
            timeout=300,
            stream=True,
        )
        for line in resp.iter_lines():
            if line:
                try:
                    data = json.loads(line)
                    if data.get("status") == "success":
                        return True
                except json.JSONDecodeError:
                    pass
        return _check_model_available()
    except Exception as exc:
        _status(f"Model pull failed: {exc}", "err")
        return False


def _build_ai_context(result: ScanResult) -> str:
    context_parts: list[str] = []

    total_secrets = sum(len(v) for v in result.secrets.values())
    total_endpoints = sum(len(v) for v in result.endpoints.values())
    total_domxss = sum(len(v) for v in result.domxss.values())
    total_vars = sum(len(v) for v in result.variables.values())

    context_parts.append(
        f"SCAN SUMMARY:\n"
        f"- JS Files Analyzed: {len(result.js_links)}\n"
        f"- Total Endpoints Found: {total_endpoints}\n"
        f"- Total Secrets Found: {total_secrets}\n"
        f"- Total DOM XSS Sinks: {total_domxss}\n"
        f"- Total JS Variables: {total_vars}\n"
    )

    if result.secrets:
        context_parts.append("\nSECRETS DETECTED (sample):")
        count = 0
        for url, secs in result.secrets.items():
            for s in secs[:3]:
                context_parts.append(f"  [{s['type']}] Line {s['line']}: {s['value'][:60]}")
                count += 1
                if count >= 15:
                    break
            if count >= 15:
                break

    if result.endpoints:
        context_parts.append("\nENDPOINTS DISCOVERED (sample):")
        count = 0
        for url, eps in result.endpoints.items():
            for ep in eps[:5]:
                context_parts.append(f"  {ep}")
                count += 1
                if count >= 20:
                    break
            if count >= 20:
                break

    if result.domxss:
        context_parts.append("\nDOM XSS SINKS FOUND (sample):")
        count = 0
        for url, sinks in result.domxss.items():
            for sink in sinks[:3]:
                context_parts.append(f"  [{sink['sink']}] Line {sink['line']}: {sink['context'][:80]}")
                count += 1
                if count >= 10:
                    break
            if count >= 10:
                break

    if result.variables:
        sample_vars: list[str] = []
        for vars_list in result.variables.values():
            sample_vars.extend(vars_list[:5])
            if len(sample_vars) >= 20:
                break
        context_parts.append(f"\nJS VARIABLES (sample): {', '.join(sample_vars[:20])}")

    full_context = "\n".join(context_parts)
    return full_context[:MAX_AI_CHUNK_CHARS]


def _sanitize_ai_prompt(user_data: str) -> str:
    user_data = re.sub(r"(?i)(ignore (previous|prior|above)|disregard|forget|pretend)", "[FILTERED]", user_data)
    user_data = re.sub(r"(?i)(system\s*:|assistant\s*:|human\s*:|<\|[a-zA-Z]+\|>)", "[FILTERED]", user_data)
    user_data = re.sub(r"(?i)(jailbreak|bypass|override|unlock|unrestricted)", "[FILTERED]", user_data)
    return user_data[:MAX_AI_CHUNK_CHARS]


def query_ollama(prompt: str) -> Optional[str]:
    try:
        payload = {
            "model": OLLAMA_MODEL,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.1,
                "top_p": 0.9,
                "num_predict": 512,
                "stop": ["###", "---END---", "Human:", "User:"],
            },
        }
        resp = requests.post(
            f"{OLLAMA_BASE_URL}/api/generate",
            json=payload,
            timeout=120,
        )
        if resp.status_code == 200:
            data = resp.json()
            return data.get("response", "").strip()
        return None
    except Exception:
        return None


def run_ai_analysis(result: ScanResult) -> None:
    _status("Starting AI analysis with Ollama (Llama 3.2:1b)...", "info")

    if not _check_ollama_available():
        _status("Ollama is not running. Start Ollama and retry.", "err")
        result.ai_analysis["error"] = "Ollama service unavailable at " + OLLAMA_BASE_URL
        return

    if not _pull_model_if_needed():
        _status("Model not available. Install Ollama and run: ollama pull llama3.2:1b", "err")
        result.ai_analysis["error"] = f"Model {OLLAMA_MODEL} not available"
        return

    context = _build_ai_context(result)
    sanitized_context = _sanitize_ai_prompt(context)

    analyses = {
        "security_assessment": (
            "You are a senior application security expert. Analyze this JavaScript recon scan data "
            "and provide a concise security assessment. Focus on critical findings, risk levels, "
            "and potential attack vectors. Be factual and technical.\n\n"
            "SCAN DATA:\n" + sanitized_context + "\n\n"
            "Provide: 1) Critical risks 2) Interesting endpoints 3) Secret exposure severity "
            "4) DOM XSS exploitability 5) Overall risk rating (Critical/High/Medium/Low)"
        ),
        "exploitation_guidance": (
            "You are a penetration tester analyzing JavaScript recon results for an authorized security test. "
            "Based on the findings below, describe potential exploitation paths a tester should investigate. "
            "Focus on technical accuracy for legitimate security testing.\n\n"
            "SCAN DATA:\n" + sanitized_context + "\n\n"
            "Provide concise exploitation guidance for: 1) Exposed secrets/tokens "
            "2) Interesting API endpoints 3) DOM XSS sink chains"
        ),
        "remediation_advice": (
            "You are a secure code reviewer. Based on the JavaScript scan findings, "
            "provide remediation advice for the development team.\n\n"
            "SCAN DATA:\n" + sanitized_context + "\n\n"
            "Provide specific, actionable remediation steps for: "
            "1) Secret management 2) DOM XSS prevention 3) API security hardening"
        ),
    }

    for analysis_type, prompt in analyses.items():
        _status(f"Running AI analysis: {c(analysis_type.replace('_', ' ').title(), ANSI_CYAN)}", "info")
        response = query_ollama(prompt)
        if response:
            result.ai_analysis[analysis_type] = response
            _status(f"AI {analysis_type} complete", "ok")
        else:
            result.ai_analysis[analysis_type] = "Analysis failed or timed out."
            _status(f"AI {analysis_type} failed", "warn")


def generate_html_report(result: ScanResult, output_path: Path) -> None:
    scan_duration = time.time() - result.scan_start
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    total_secrets = sum(len(v) for v in result.secrets.values())
    total_endpoints = sum(len(v) for v in result.endpoints.values())
    total_domxss = sum(len(v) for v in result.domxss.values())
    total_vars = sum(len(v) for v in result.variables.values())

    def e(text: str) -> str:
        return html.escape(str(text))

    def render_table_rows(items: list, columns: list[str]) -> str:
        rows = []
        for item in items:
            cells = "".join(f"<td>{e(item.get(col, ''))}</td>" for col in columns)
            rows.append(f"<tr>{cells}</tr>")
        return "\n".join(rows)

    secrets_html = ""
    for url, secs in result.secrets.items():
        rows = render_table_rows(secs, ["type", "line", "value", "context"])
        secrets_html += f"""
        <div class="js-file-section">
          <h4>üìÑ {e(url)}</h4>
          <table>
            <thead><tr><th>Type</th><th>Line</th><th>Value</th><th>Context</th></tr></thead>
            <tbody>{rows}</tbody>
          </table>
        </div>"""

    endpoints_html = ""
    for url, eps in result.endpoints.items():
        items = "".join(f"<li><code>{e(ep)}</code></li>" for ep in eps)
        endpoints_html += f"""
        <div class="js-file-section">
          <h4>üìÑ {e(url)}</h4>
          <ul>{items}</ul>
        </div>"""

    domxss_html = ""
    for url, sinks in result.domxss.items():
        rows = render_table_rows(sinks, ["sink", "line", "context"])
        domxss_html += f"""
        <div class="js-file-section">
          <h4>üìÑ {e(url)}</h4>
          <table>
            <thead><tr><th>Sink</th><th>Line</th><th>Context</th></tr></thead>
            <tbody>{rows}</tbody>
          </table>
        </div>"""

    variables_html = ""
    for url, vars_list in result.variables.items():
        items = "".join(f"<li><code>{e(v)}</code></li>" for v in vars_list)
        variables_html += f"""
        <div class="js-file-section">
          <h4>üìÑ {e(url)}</h4>
          <ul class="var-list">{items}</ul>
        </div>"""

    js_links_html = "".join(f"<li><a href='{e(l)}' target='_blank'>{e(l)}</a></li>" for l in result.js_links)
    wordlist_html = "".join(f"<li><code>{e(w)}</code></li>" for w in result.wordlist[:500])

    ai_html = ""
    for key, value in result.ai_analysis.items():
        title = key.replace("_", " ").title()
        ai_html += f"""
        <div class="ai-section">
          <h3>ü§ñ {e(title)}</h3>
          <div class="ai-content"><pre>{e(value)}</pre></div>
        </div>"""

    errors_html = "".join(f"<li>{e(err)}</li>" for err in result.errors[:50])

    report_html = f"""<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>JSNinja Report - {e(timestamp)}</title>
  <style>
    :root {{
      --bg: #0d1117; --surface: #161b22; --border: #30363d;
      --text: #c9d1d9; --text-dim: #8b949e; --accent: #58a6ff;
      --green: #3fb950; --red: #f85149; --yellow: #d29922; --purple: #bc8cff;
      --cyan: #39c5cf;
    }}
    * {{ box-sizing: border-box; margin: 0; padding: 0; }}
    body {{ background: var(--bg); color: var(--text); font-family: -apple-system,BlinkMacSystemFont,'Segoe UI',monospace; font-size: 14px; }}
    header {{ background: linear-gradient(135deg, #0d1117 0%, #161b22 100%); border-bottom: 1px solid var(--border); padding: 24px 32px; display: flex; align-items: center; gap: 16px; }}
    .logo {{ font-size: 28px; font-weight: 900; background: linear-gradient(90deg, var(--cyan), var(--accent)); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }}
    .meta {{ color: var(--text-dim); font-size: 12px; margin-top: 4px; }}
    nav {{ background: var(--surface); border-bottom: 1px solid var(--border); display: flex; flex-wrap: wrap; gap: 2px; padding: 8px 32px; }}
    nav a {{ color: var(--text-dim); text-decoration: none; padding: 6px 14px; border-radius: 6px; font-size: 13px; transition: all 0.2s; }}
    nav a:hover, nav a.active {{ background: var(--accent); color: white; }}
    main {{ padding: 32px; max-width: 1400px; margin: 0 auto; }}
    .stats-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(160px, 1fr)); gap: 16px; margin-bottom: 32px; }}
    .stat-card {{ background: var(--surface); border: 1px solid var(--border); border-radius: 10px; padding: 20px; text-align: center; }}
    .stat-card .number {{ font-size: 32px; font-weight: 700; }}
    .stat-card .label {{ color: var(--text-dim); font-size: 12px; margin-top: 4px; }}
    .stat-card.danger .number {{ color: var(--red); }}
    .stat-card.warn .number {{ color: var(--yellow); }}
    .stat-card.info .number {{ color: var(--accent); }}
    .stat-card.ok .number {{ color: var(--green); }}
    section {{ margin-bottom: 40px; display: none; }}
    section.active {{ display: block; }}
    h2 {{ font-size: 18px; margin-bottom: 16px; padding-bottom: 8px; border-bottom: 1px solid var(--border); color: var(--accent); }}
    .js-file-section {{ margin-bottom: 20px; background: var(--surface); border: 1px solid var(--border); border-radius: 8px; overflow: hidden; }}
    .js-file-section h4 {{ padding: 10px 16px; background: #1c2128; font-size: 12px; color: var(--text-dim); word-break: break-all; border-bottom: 1px solid var(--border); }}
    table {{ width: 100%; border-collapse: collapse; font-size: 12px; }}
    th {{ background: #1c2128; padding: 8px 12px; text-align: left; color: var(--text-dim); font-weight: 600; border-bottom: 1px solid var(--border); }}
    td {{ padding: 8px 12px; border-bottom: 1px solid var(--border); word-break: break-all; max-width: 400px; }}
    tr:last-child td {{ border-bottom: none; }}
    tr:hover td {{ background: rgba(88,166,255,0.05); }}
    ul {{ list-style: none; padding: 12px 16px; }}
    ul li {{ padding: 4px 0; border-bottom: 1px solid var(--border); font-size: 12px; }}
    ul li:last-child {{ border-bottom: none; }}
    .var-list {{ display: flex; flex-wrap: wrap; gap: 6px; padding: 12px; }}
    .var-list li {{ border: none; padding: 0; }}
    code {{ background: #1c2128; padding: 2px 6px; border-radius: 4px; font-family: monospace; font-size: 11px; color: var(--cyan); }}
    a {{ color: var(--accent); text-decoration: none; }}
    a:hover {{ text-decoration: underline; }}
    .ai-section {{ background: var(--surface); border: 1px solid var(--border); border-radius: 10px; padding: 20px; margin-bottom: 20px; }}
    .ai-section h3 {{ margin-bottom: 12px; color: var(--purple); }}
    .ai-content pre {{ white-space: pre-wrap; font-size: 13px; line-height: 1.6; font-family: -apple-system,BlinkMacSystemFont,'Segoe UI',sans-serif; }}
    .badge {{ display: inline-block; padding: 2px 8px; border-radius: 12px; font-size: 11px; font-weight: 600; }}
    .badge.red {{ background: rgba(248,81,73,0.15); color: var(--red); border: 1px solid rgba(248,81,73,0.3); }}
    .badge.yellow {{ background: rgba(210,153,34,0.15); color: var(--yellow); border: 1px solid rgba(210,153,34,0.3); }}
    .empty {{ color: var(--text-dim); padding: 20px; text-align: center; font-style: italic; }}
    footer {{ text-align: center; color: var(--text-dim); padding: 24px; font-size: 12px; border-top: 1px solid var(--border); margin-top: 40px; }}
  </style>
</head>
<body>
  <header>
    <div>
      <div class="logo">‚ö° JSNinja</div>
      <div class="meta">JavaScript Reconnaissance Report &nbsp;|&nbsp; {e(timestamp)} &nbsp;|&nbsp; Duration: {scan_duration:.1f}s &nbsp;|&nbsp; v{__version__}</div>
    </div>
  </header>
  <nav>
    <a href="#" class="active" onclick="show('overview')">üìä Overview</a>
    <a href="#" onclick="show('jslinks')">üîó JS Links ({len(result.js_links)})</a>
    <a href="#" onclick="show('endpoints')">üéØ Endpoints ({total_endpoints})</a>
    <a href="#" onclick="show('secrets')">üîë Secrets ({total_secrets})</a>
    <a href="#" onclick="show('domxss')">‚ö†Ô∏è DOM XSS ({total_domxss})</a>
    <a href="#" onclick="show('variables')">üìù Variables ({total_vars})</a>
    <a href="#" onclick="show('wordlist')">üìö Wordlist ({len(result.wordlist)})</a>
    <a href="#" onclick="show('ai')">ü§ñ AI Analysis</a>
    <a href="#" onclick="show('errors')">‚ùå Errors ({len(result.errors)})</a>
  </nav>
  <main>
    <div class="stats-grid">
      <div class="stat-card info"><div class="number">{len(result.js_links)}</div><div class="label">JS Files</div></div>
      <div class="stat-card info"><div class="number">{total_endpoints}</div><div class="label">Endpoints</div></div>
      <div class="stat-card danger"><div class="number">{total_secrets}</div><div class="label">Secrets</div></div>
      <div class="stat-card warn"><div class="number">{total_domxss}</div><div class="label">DOM XSS Sinks</div></div>
      <div class="stat-card ok"><div class="number">{total_vars}</div><div class="label">Variables</div></div>
      <div class="stat-card ok"><div class="number">{len(result.wordlist)}</div><div class="label">Wordlist Items</div></div>
    </div>

    <section id="overview" class="active">
      <h2>üìä Scan Overview</h2>
      <p style="color:var(--text-dim);line-height:1.6;">
        JSNinja scanned <strong style="color:var(--text)">{len(result.js_links)}</strong> JavaScript files,
        discovered <strong style="color:var(--accent)">{total_endpoints}</strong> endpoints,
        detected <strong style="color:var(--red)">{total_secrets}</strong> potential secrets,
        identified <strong style="color:var(--yellow)">{total_domxss}</strong> DOM XSS sinks,
        and extracted <strong style="color:var(--green)">{total_vars}</strong> JavaScript variables
        for further analysis. Scan completed in {scan_duration:.1f} seconds.
      </p>
    </section>

    <section id="jslinks">
      <h2>üîó JavaScript File Links</h2>
      {f'<ul>{js_links_html}</ul>' if result.js_links else '<div class="empty">No JS links found.</div>'}
    </section>

    <section id="endpoints">
      <h2>üéØ Extracted Endpoints</h2>
      {endpoints_html if result.endpoints else '<div class="empty">No endpoints found.</div>'}
    </section>

    <section id="secrets">
      <h2>üîë Secrets & Sensitive Data</h2>
      {secrets_html if result.secrets else '<div class="empty">No secrets detected.</div>'}
    </section>

    <section id="domxss">
      <h2>‚ö†Ô∏è DOM XSS Sinks</h2>
      {domxss_html if result.domxss else '<div class="empty">No DOM XSS sinks found.</div>'}
    </section>

    <section id="variables">
      <h2>üìù JavaScript Variables</h2>
      {variables_html if result.variables else '<div class="empty">No variables extracted.</div>'}
    </section>

    <section id="wordlist">
      <h2>üìö Generated Wordlist (Top 500)</h2>
      {f'<ul class="var-list">{wordlist_html}</ul>' if result.wordlist else '<div class="empty">No wordlist generated.</div>'}
    </section>

    <section id="ai">
      <h2>ü§ñ AI Security Analysis (Llama 3.2)</h2>
      {ai_html if result.ai_analysis else '<div class="empty">AI analysis not performed.</div>'}
    </section>

    <section id="errors">
      <h2>‚ùå Scan Errors</h2>
      {f'<ul>{errors_html}</ul>' if result.errors else '<div class="empty">No errors encountered.</div>'}
    </section>
  </main>
  <footer>JSNinja v{__version__} | Generated {e(timestamp)} | For authorized security testing only</footer>
  <script>
    function show(id) {{
      document.querySelectorAll('section').forEach(s => s.classList.remove('active'));
      document.querySelectorAll('nav a').forEach(a => a.classList.remove('active'));
      document.getElementById(id).classList.add('active');
      event.target.classList.add('active');
    }}
  </script>
</body>
</html>"""

    output_path.write_text(report_html, encoding="utf-8")
    _status(f"HTML report saved: {c(str(output_path), ANSI_GREEN)}", "ok")


def save_text_outputs(result: ScanResult, output_dir: Path) -> None:
    output_dir.mkdir(parents=True, exist_ok=True)

    if result.js_links:
        p = output_dir / "js_links.txt"
        p.write_text("\n".join(result.js_links) + "\n", encoding="utf-8")
        _status(f"JS links ‚Üí {c(str(p), ANSI_GREEN)}", "ok")

    if result.endpoints:
        all_eps: list[str] = []
        for eps in result.endpoints.values():
            all_eps.extend(eps)
        p = output_dir / "endpoints.txt"
        p.write_text("\n".join(sorted(set(all_eps))) + "\n", encoding="utf-8")
        _status(f"Endpoints ‚Üí {c(str(p), ANSI_GREEN)}", "ok")

    if result.secrets:
        lines: list[str] = []
        for url, secs in result.secrets.items():
            for s in secs:
                lines.append(f"[{s['type']}] {url}:{s['line']} ‚Üí {s['value']}")
        p = output_dir / "secrets.txt"
        p.write_text("\n".join(lines) + "\n", encoding="utf-8")
        _status(f"Secrets ‚Üí {c(str(p), ANSI_GREEN)}", "ok")

    if result.domxss:
        lines = []
        for url, sinks in result.domxss.items():
            for sk in sinks:
                lines.append(f"[{sk['sink']}] {url}:{sk['line']} ‚Üí {sk['context']}")
        p = output_dir / "domxss.txt"
        p.write_text("\n".join(lines) + "\n", encoding="utf-8")
        _status(f"DOM XSS ‚Üí {c(str(p), ANSI_GREEN)}", "ok")

    if result.variables:
        all_vars: set[str] = set()
        for v_list in result.variables.values():
            all_vars.update(v_list)
        p = output_dir / "variables.txt"
        p.write_text("\n".join(sorted(all_vars)) + "\n", encoding="utf-8")
        _status(f"Variables ‚Üí {c(str(p), ANSI_GREEN)}", "ok")

    if result.wordlist:
        p = output_dir / "wordlist.txt"
        p.write_text("\n".join(result.wordlist) + "\n", encoding="utf-8")
        _status(f"Wordlist ‚Üí {c(str(p), ANSI_GREEN)}", "ok")

    if result.ai_analysis:
        ai_lines: list[str] = []
        for key, value in result.ai_analysis.items():
            ai_lines.append(f"=== {key.replace('_', ' ').upper()} ===\n{value}\n")
        p = output_dir / "ai_analysis.txt"
        p.write_text("\n".join(ai_lines), encoding="utf-8")
        _status(f"AI analysis ‚Üí {c(str(p), ANSI_GREEN)}", "ok")


def print_summary(result: ScanResult) -> None:
    duration = time.time() - result.scan_start
    print()
    print(c("  ‚îÄ" * 35, ANSI_DIM))
    print(c("  SCAN SUMMARY", ANSI_BOLD))
    print(c("  ‚îÄ" * 35, ANSI_DIM))
    summary = [
        ("JS Files Discovered", len(result.js_links), ANSI_CYAN),
        ("Endpoints Found", sum(len(v) for v in result.endpoints.values()), ANSI_BLUE),
        ("Secrets Detected", sum(len(v) for v in result.secrets.values()), ANSI_RED),
        ("DOM XSS Sinks", sum(len(v) for v in result.domxss.values()), ANSI_YELLOW),
        ("Variables Extracted", sum(len(v) for v in result.variables.values()), ANSI_GREEN),
        ("Wordlist Words", len(result.wordlist), ANSI_GREEN),
        ("Errors", len(result.errors), ANSI_RED if result.errors else ANSI_GREEN),
    ]
    for label, value, color in summary:
        print(f"  {c(label + ':', ANSI_DIM):<30} {c(str(value), color, ANSI_BOLD)}")
    print(f"  {c('Duration:', ANSI_DIM):<30} {c(f'{duration:.1f}s', ANSI_CYAN)}")
    print(c("  ‚îÄ" * 35, ANSI_DIM))
    print()


def build_argument_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        prog="jsninja",
        description="JSNinja - JavaScript Reconnaissance & AI Analysis Engine",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python jsninja.py -l targets.txt -e -s -o ./output
  python jsninja.py -f js_urls.txt -e -s -d -w -a -r -o ./output
  python jsninja.py -l targets.txt --all -o ./results
  python jsninja.py -f js_urls.txt -s -a -r -o ./output

Target file format (for -l):
  https://example.com
  https://sub.example.com

For authorized security testing only.
        """,
    )
    input_group = parser.add_argument_group("Input")
    input_group.add_argument("-l", "--links", metavar="FILE", help="File of target URLs to crawl for JS links")
    input_group.add_argument("-f", "--file", metavar="FILE", help="File containing direct JS file URLs")

    scan_group = parser.add_argument_group("Scan Modules")
    scan_group.add_argument("-e", "--endpoints", action="store_true", help="Extract endpoints from JS files")
    scan_group.add_argument("-s", "--secrets", action="store_true", help="Find secrets in JS files")
    scan_group.add_argument("-d", "--domxss", action="store_true", help="Scan for DOM XSS sinks")
    scan_group.add_argument("-v", "--variables", action="store_true", help="Extract JS variable names")
    scan_group.add_argument("-w", "--wordlist", action="store_true", help="Build wordlist from JS content")
    scan_group.add_argument("-m", "--manual", action="store_true", help="Save JS files locally for manual analysis")
    scan_group.add_argument("-a", "--ai", action="store_true", help="Run AI analysis using Ollama (Llama 3.2:1b)")
    scan_group.add_argument("--all", action="store_true", dest="all_modules", help="Enable all scan modules")

    output_group = parser.add_argument_group("Output")
    output_group.add_argument("-o", "--output", metavar="DIR", default="./jsninja_output", help="Output directory (default: ./jsninja_output)")
    output_group.add_argument("-r", "--report", action="store_true", help="Generate HTML report")
    output_group.add_argument("--no-banner", action="store_true", help="Suppress the banner")
    output_group.add_argument("--no-color", action="store_true", help="Disable colored output")
    output_group.add_argument("--verbose", action="store_true", help="Enable verbose logging")
    output_group.add_argument("--version", action="version", version=f"%(prog)s {__version__}")

    return parser


def _load_urls_from_file(filepath: str, label: str) -> list[str]:
    path = Path(filepath)
    if not path.exists():
        _status(f"{label} file not found: {filepath}", "err")
        sys.exit(1)
    if not path.is_file():
        _status(f"{label} path is not a file: {filepath}", "err")
        sys.exit(1)

    try:
        raw = path.read_text(encoding="utf-8", errors="replace")
    except OSError as exc:
        _status(f"Cannot read {label} file: {exc}", "err")
        sys.exit(1)

    urls: list[str] = []
    for line in raw.splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        safe = _sanitize_url(line)
        if safe:
            urls.append(safe)
        else:
            logger.warning("Skipping invalid URL: %s", line)
    return urls


def _signal_handler(sig: int, frame: object) -> None:
    print(f"\n{c('  [!] Interrupted by user. Exiting...', ANSI_YELLOW)}")
    sys.exit(130)


def main() -> None:
    signal.signal(signal.SIGINT, _signal_handler)

    parser = build_argument_parser()
    args = parser.parse_args()

    global USE_COLOR
    if args.no_color:
        USE_COLOR = False

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
        logger.setLevel(logging.DEBUG)

    if not args.no_banner:
        print_banner()

    if not args.links and not args.file:
        _status("No input provided. Use -l <targets.txt> or -f <js_urls.txt>", "err")
        parser.print_help()
        sys.exit(1)

    if args.all_modules:
        args.endpoints = args.secrets = args.domxss = args.variables = True
        args.wordlist = args.manual = args.ai = args.report = True

    output_dir = Path(args.output).resolve()

    try:
        output_dir.mkdir(parents=True, exist_ok=True)
    except OSError as exc:
        _status(f"Cannot create output directory: {exc}", "err")
        sys.exit(1)

    result = ScanResult()

    if args.links:
        targets = _load_urls_from_file(args.links, "Targets")
        if not targets:
            _status("No valid target URLs found in file", "err")
            sys.exit(1)
        _status(f"Loaded {c(str(len(targets)), ANSI_GREEN)} target URLs", "ok")
        discover_js_links(targets, result)

    if args.file:
        js_urls = _load_urls_from_file(args.file, "JS URLs")
        if not js_urls:
            _status("No valid JS URLs found in file", "err")
            sys.exit(1)
        _status(f"Loaded {c(str(len(js_urls)), ANSI_GREEN)} JS URLs from file", "ok")
        existing = set(result.js_links)
        for url in js_urls:
            if url not in existing:
                result.js_links.append(url)

    if not result.js_links:
        _status("No JS files to process. Exiting.", "warn")
        sys.exit(0)

    any_scan = any([args.endpoints, args.secrets, args.domxss, args.variables, args.wordlist, args.manual])

    if any_scan:
        run_scan(
            js_links=result.js_links,
            output_dir=output_dir,
            result=result,
            do_endpoints=args.endpoints,
            do_secrets=args.secrets,
            do_domxss=args.domxss,
            do_variables=args.variables,
            do_wordlist=args.wordlist,
            do_local=args.manual,
        )

    if any_scan:
        save_text_outputs(result, output_dir)

    if args.ai:
        run_ai_analysis(result)
        if result.ai_analysis and "error" not in result.ai_analysis:
            ai_lines = []
            for key, val in result.ai_analysis.items():
                ai_lines.append(f"=== {key.replace('_', ' ').upper()} ===\n{val}\n")
            ai_path = output_dir / "ai_analysis.txt"
            ai_path.write_text("\n".join(ai_lines), encoding="utf-8")

    if args.report:
        report_path = output_dir / "report.html"
        generate_html_report(result, report_path)

    print_summary(result)

    if result.secrets:
        _status(
            f"‚ö†Ô∏è  {c(str(sum(len(v) for v in result.secrets.values())), ANSI_RED, ANSI_BOLD)} potential secrets found! Review secrets.txt immediately.",
            "warn",
        )
    if result.domxss:
        _status(
            f"‚ö†Ô∏è  {c(str(sum(len(v) for v in result.domxss.values())), ANSI_YELLOW, ANSI_BOLD)} DOM XSS sinks identified. Review domxss.txt.",
            "warn",
        )

if __name__ == "__main__":
    main()
